{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split - Creation of train & test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tries to mimic the train_test_split function from scikit-learn, to work on images located in a folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-required-Libraries\" data-toc-modified-id=\"Import-required-Libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import required Libraries</a></span></li><li><span><a href=\"#Function-definition\" data-toc-modified-id=\"Function-definition-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Function definition</a></span></li><li><span><a href=\"#Example-usage\" data-toc-modified-id=\"Example-usage-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Example usage</a></span></li><li><span><a href=\"#Merge-folders,-if-required\" data-toc-modified-id=\"Merge-folders,-if-required-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Merge folders, if required</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:44:16.227656Z",
     "start_time": "2019-05-26T12:44:14.023680Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from keras_preprocessing.image.utils import _iter_valid_files\n",
    "from keras_preprocessing.image.directory_iterator import DirectoryIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions to get list of images in a path, and rename them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:44:54.992369Z",
     "start_time": "2019-05-26T12:44:54.985557Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_valid_images_in_path(path):\n",
    "    \"\"\"\n",
    "    Return a list of valid images in a path\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        \n",
    "        path: str\n",
    "            Location where the images are stored\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        \n",
    "        list of str: List of images obtained from the directory\n",
    "        \n",
    "    \"\"\"\n",
    "    from keras_preprocessing.image.utils import _iter_valid_files\n",
    "    from keras_preprocessing.image.directory_iterator import DirectoryIterator\n",
    "    \n",
    "    list_files = list(\n",
    "        _iter_valid_files(path,\n",
    "                          DirectoryIterator.white_list_formats,\n",
    "                          follow_links=False))\n",
    "    list_files = list(map(lambda x: os.path.join(*x), list_files))\n",
    "    return list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function to create train & test splits of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:44:55.343076Z",
     "start_time": "2019-05-26T12:44:55.319384Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_test_split_images(path_input,\n",
    "                            path_output_train,\n",
    "                            path_output_test,\n",
    "                            stratify=False,\n",
    "                            **kwargs):\n",
    "    \"\"\"\n",
    "    Used to create train_test splits of images found in directories, and store them in a particular location. \n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        \n",
    "        path_input: str\n",
    "            Location where the input images are stored. The folder structure for identifying images across classes should be same as that expected by keras.preprocessing.image.ImageDataGenerator\n",
    "        path_output_train: str\n",
    "            Location where the train image set will be placed after creating train/test splits from the input\n",
    "        path_output_test: str\n",
    "            Location where the train image set will be placed after creating train/test splits from the input\n",
    "        stratify: bool\n",
    "            Whether the split of train and test should be based on stratified sampling, to account for the volume proportions of available classes (Defaults to False, i.e., random sampling)\n",
    "        \n",
    "        **kwargs: dict like\n",
    "            All other parameters passed to sklearn's train_test_split method.\n",
    "                - test_size : float, int or None, optional (default=0.25)\n",
    "                - train_size : float, int, or None, (default=None)\n",
    "                - random_state : int, RandomState instance or None, optional (default=None)\n",
    "                - shuffle : boolean, optional (default=True)\n",
    "    \"\"\"\n",
    "    # Check if path_output_train and path_output_test exist. If not, they are created\n",
    "\n",
    "    for path_op in [path_output_train, path_output_test]:\n",
    "        if not os.path.exists(path_op):\n",
    "            os.mkdir(path_op)\n",
    "            print(\"Path created: %s\" % path_op)\n",
    "\n",
    "    # Identify the list of available categories/classes\n",
    "    classes = []\n",
    "    for subdir in sorted(os.listdir(path_input)):\n",
    "        if os.path.isdir(os.path.join(path_input, subdir)):\n",
    "            classes.append(subdir)\n",
    "\n",
    "    # Create a dataframe containing the list of images belonging to each class (Identified from the specified location)\n",
    "    list_valid_files = []\n",
    "    i = 0\n",
    "    for dirpath in (os.path.join(path_input, subdir) for subdir in classes):\n",
    "        #     print(os.listdir(dirpath))\n",
    "        list_files = get_valid_images_in_path(dirpath)        \n",
    "        list_valid_files.extend(\n",
    "            list(zip(np.repeat(classes[i], len(list_files)), list_files)))\n",
    "        i += 1\n",
    "\n",
    "    data_valid_files = pd.DataFrame(\n",
    "        list_valid_files,\n",
    "        columns=['class', 'path'])  # Store the list_valid_files in a dataframe\n",
    "\n",
    "    # Create Train-Test splits from the dataframe\n",
    "    flag_stratify = data_valid_files['class'] if (stratify == True) else None\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data_valid_files['path'],\n",
    "        data_valid_files['class'],\n",
    "        stratify=flag_stratify,\n",
    "        **kwargs)\n",
    "    # print(\"Training Data:\\n\\n\",pd.Series(y_train).value_counts())\n",
    "    # print(\"Test Data:\\n\\n\",pd.Series(y_test).value_counts())\n",
    "\n",
    "    # Create a dataframe to store all the configuration variables required for copying files\n",
    "    data_result = pd.concat([\n",
    "        pd.DataFrame({\n",
    "            'path': X_train,\n",
    "            'class': y_train,\n",
    "            'type': np.repeat('train', len(X_train))\n",
    "        }),\n",
    "        pd.DataFrame({\n",
    "            'path': X_test,\n",
    "            'class': y_test,\n",
    "            'type': np.repeat('test', len(X_test))\n",
    "        })\n",
    "    ])\n",
    "    # Identify the output paths for each image\n",
    "    data_result['path_output_base'] = np.where(data_result['type'] == 'train',\n",
    "                                               path_output_train,\n",
    "                                               path_output_test)\n",
    "    data_result['path_output'] = data_result.apply(lambda x: os.path.join(\n",
    "        x['path_output_base'], x['class'], os.path.basename(x['path'])),\n",
    "                                                   axis=1)\n",
    "\n",
    "    # Ensure that the required o/p directories exist. If not, they will be created\n",
    "    for feature in data_result['class'].unique():\n",
    "        for path_op in [path_output_train, path_output_test]:\n",
    "            folder = os.path.join(path_op, feature)\n",
    "            if not os.path.exists(folder):\n",
    "                os.mkdir(folder)\n",
    "\n",
    "    # Copy the files to the respective locations\n",
    "    data_result.apply(lambda x: shutil.copyfile(x['path'], x['path_output']),\n",
    "                      axis=1)\n",
    "    print(\n",
    "        \"Samples have been created. \\n\\nSummary\\n------\\n\\nTotal number of samples:%s. \\nVolumes across categories:\\n\"\n",
    "        % data_result.shape[0],\n",
    "        data_result.groupby(['type', 'class']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:44:58.877594Z",
     "start_time": "2019-05-26T12:44:58.873032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Folders where the input files must be present & output files must be placed. Should be valid paths \n",
    "PATH_INPUT = r'/Users/shyamravikumar/Documents/Workspace/BAI - Project/Input Files/V4/2. Renamed Images'\n",
    "PATH_OUTPUT = r'/Users/shyamravikumar/Documents/Workspace/BAI - Project/Input Files/V4/3. Train Test Split'\n",
    "\n",
    "# Train and test folders will be created inside these paths, containing the required images\n",
    "PATH_OUTPUT_TRAIN = os.path.join(PATH_OUTPUT,'train')\n",
    "PATH_OUTPUT_TEST = os.path.join(PATH_OUTPUT,'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the paths are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:45:04.763081Z",
     "start_time": "2019-05-26T12:45:04.755415Z"
    }
   },
   "outputs": [],
   "source": [
    "check_exists_path = lambda x: os.path.exists(x)\n",
    "assert(check_exists_path(PATH_INPUT))\n",
    "assert(check_exists_path(PATH_OUTPUT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T12:45:10.940126Z",
     "start_time": "2019-05-26T12:45:10.171527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: /Users/shyamravikumar/Documents/Workspace/BAI - Project/Input Files/V4/3. Train Test Split/train\n",
      "Path created: /Users/shyamravikumar/Documents/Workspace/BAI - Project/Input Files/V4/3. Train Test Split/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/bai_project_py/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples have been created. \n",
      "\n",
      "Summary\n",
      "------\n",
      "\n",
      "Total number of samples:149. \n",
      "Volumes across categories:\n",
      " type   class                \n",
      "test   LAV-P1                    4\n",
      "       LAV-P2                    2\n",
      "       LAV-P3                    3\n",
      "       LDL-P1                    1\n",
      "       LDL-P2                    4\n",
      "       LDL-P3                    1\n",
      "       LDL-P4                    2\n",
      "       Not Defective            28\n",
      "       Not Defective Bubbles    15\n",
      "train  LAV-P1                    6\n",
      "       LAV-P2                    2\n",
      "       LAV-P3                    4\n",
      "       LDL-P1                    2\n",
      "       LDL-P2                    7\n",
      "       LDL-P3                    3\n",
      "       LDL-P4                    2\n",
      "       Not Defective            41\n",
      "       Not Defective Bubbles    22\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_test_split_images(\n",
    "    path_input=PATH_INPUT,\n",
    "    path_output_train=PATH_OUTPUT_TRAIN,\n",
    "    path_output_test=PATH_OUTPUT_TEST,\n",
    "    stratify=True,\n",
    "    train_size=0.6,\n",
    "    random_state=12334  \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BAI)",
   "language": "python",
   "name": "bai_project_py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
